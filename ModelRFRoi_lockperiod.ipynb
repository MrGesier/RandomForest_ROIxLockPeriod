import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# Load the model from the file
with open('rf_model_sale_rev05.pkl', 'rb') as f:
    rf_model_sale = pickle.load(f)

# Input variables
drift = 0.10
sigma = 0.35
period = 600
num_runs = 6000
average_vesting_price = 0.3  # Your average vesting price

# Tables
vesting_schedule = pd.read_excel("Modified_Vesting_Schedule _daily.xlsx")

# Get the length of the vesting schedule
vesting_period = len(vesting_schedule)

# Adjust the period in Black-Scholes simulations to match the vesting period
period = vesting_period

# Define a function to calculate the cumulative tokens sold for a given starting price
def calculate_cumulative_tokens_sold(start_price):
    # Adjust the starting price
    average_vesting_price = start_price

    # Re-run the price simulations
    price_scenarios = []
    for run in range(num_runs):
        prices = [average_vesting_price]  # We start with the average vesting price as the initial price
        for day in range(1, period):
            new_price = prices[-1] * np.exp((drift - 0.5 * sigma**2) + sigma * np.random.normal(0, 1))
            if day == 90 and new_price > 10 * average_vesting_price:  # Stop if price increases by 50x in the first 3 months
                break
            prices.append(new_price)
        price_scenarios.append(prices)

    # Filter out the simulations that were stopped
    price_scenarios = [prices for prices in price_scenarios if len(prices) == period]

    # Convert the list of lists into a NumPy array
    price_scenarios = np.array(price_scenarios)

    # Calculation of the Black-Scholes minimum, median, and maximum for each day
    min_prices = np.min(price_scenarios, axis=0)
    median_prices = np.median(price_scenarios, axis=0)
    max_prices = np.max(price_scenarios, axis=0)

    # Calculation of the ROI for each scenario
    rois = (median_prices - average_vesting_price) / average_vesting_price

    # Function to compute the sell probability based on ROI and Dormancy
    def compute_sell_probability(roi, dormancy):
        input_data_sale = np.array([[roi, dormancy]])
        prob_sale = rf_model_sale.predict_proba(input_data_sale)[:, 1]
        noise = np.random.normal(0, 0.025)  # Add Gaussian noise
        return np.clip(prob_sale + noise, 0, 1)

    # Calculate the sell probability for each day of the vesting period
    for i, row in vesting_schedule.iterrows():
        roi = rois[i % period]
        dormancy = row["Dormancy"]
        vesting_schedule.at[i, "Sell Probability"] = compute_sell_probability(roi, dormancy)

    # Calculation of the number of tokens sold and held
    vesting_schedule["Tokens Sold"] = vesting_schedule["Sell Probability"] * vesting_schedule["Tokens Unlocked"]
    vesting_schedule["Tokens Held"] = vesting_schedule["Tokens Unlocked"] - vesting_schedule["Tokens Sold"]

    # Calculate the cumulative number of tokens sold
    cumulative_tokens_sold = vesting_schedule["Tokens Sold"].cumsum()

    return cumulative_tokens_sold, vesting_schedule, price_scenarios

# Calculate the cumulative tokens sold for the original, increased and decreased starting prices
cumulative_tokens_sold_original, vesting_schedule_original, price_scenarios_original = calculate_cumulative_tokens_sold(average_vesting_price)
cumulative_tokens_sold_increased, _, _ = calculate_cumulative_tokens_sold(average_vesting_price * 2)
cumulative_tokens_sold_decreased, _, _ = calculate_cumulative_tokens_sold(average_vesting_price * 0.2)

# Calculate the total tokens sold for the original, increased and decreased starting prices
total_tokens_sold_original = cumulative_tokens_sold_original.iloc[-1]
total_tokens_sold_increased = cumulative_tokens_sold_increased.iloc[-1]
total_tokens_sold_decreased = cumulative_tokens_sold_decreased.iloc[-1]

# Calculate the percentage change in total tokens sold due to the change in starting price
perc_change_increased = (total_tokens_sold_increased - total_tokens_sold_original) / total_tokens_sold_original * 100
perc_change_decreased = (total_tokens_sold_decreased - total_tokens_sold_original) / total_tokens_sold_original * 100


# Print the results with rounding to 1 decimal places
print(f"Selling Pressure decrease due to increased starting price: {round(perc_change_increased, 1)}%")
print(f"Selling pressure decrease due to decreased starting price: {round(perc_change_decreased, 1)}%")


# Plot the cumulative tokens sold for each starting price
plt.figure(figsize=(10, 6))
plt.plot(cumulative_tokens_sold_original, label='Original Starting Price')
plt.plot(cumulative_tokens_sold_increased, label='Increased Starting Price')
plt.plot(cumulative_tokens_sold_decreased, label='Decreased Starting Price')
plt.title('Cumulative Tokens Sold for Different Starting Prices')
plt.xlabel('Days')
plt.ylabel('Cumulative Tokens Sold')
plt.legend()
plt.grid(False)
plt.show()

# Display the results
print(vesting_schedule_original)

# Generate a scatter plot of Sell Probability vs Dormancy
plt.figure(figsize=(10, 6))
sns.scatterplot(x=vesting_schedule_original["Dormancy"], y=vesting_schedule_original["Sell Probability"], alpha=0.5)
plt.title('Sell Probability vs Dormancy')
plt.xlabel('Dormancy (days)')
plt.ylabel('Sell Probability')
plt.grid(False)
plt.show()

# Replace all values above the threshold with NaN
max_price_threshold = average_vesting_price * 50
price_scenarios_original = np.where(price_scenarios_original > max_price_threshold, np.nan, price_scenarios_original)

# Calculation of the Black-Scholes minimum, median and maximum for each day
min_prices = np.nanmin(price_scenarios_original, axis=0)
median_prices = np.nanmedian(price_scenarios_original, axis=0)
max_prices = np.nanmax(price_scenarios_original, axis=0)

# Calculation of the Black-Scholes 1st quartile and 3rd quartile for each day
q1_prices = np.nanpercentile(price_scenarios_original, 25, axis=0)
q3_prices = np.nanpercentile(price_scenarios_original, 75, axis=0)

# Plotting the median prices and the probability cone from the Black-Scholes simulations
plt.figure(figsize=(10, 6))
plt.plot(range(period), median_prices, label='Median Price', color='blue')
plt.fill_between(range(period), q1_prices, q3_prices, color='blue', alpha=0.1)
plt.title('Prices from Black-Scholes Simulations with Probability Cone')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()
plt.grid(False)
plt.show()

# Setting up the subplot with secondary y-axes
fig, ax1 = plt.subplots(figsize=(14, 7))

# Plotting the Sell Probability for each unlock day on the primary y-axis (left)
ax1.plot(vesting_schedule_original.index, vesting_schedule_original["Sell Probability"], label='Sell Probability', color='purple', marker='o', markersize=4, linestyle='-')
ax1.set_title('Sell Probability, Median Price, and Tokens Sold on Each Token Unlock')
ax1.set_xlabel('Days')
ax1.set_ylabel('Sell Probability', color='purple')
ax1.legend(loc='upper left')
ax1.grid(False)

# Creating the secondary y-axis (right) for Median Price
ax2 = ax1.twinx()
ax2.plot(range(period), median_prices, label='Median Price', color='blue')
ax2.set_ylabel('Median Price', color='blue')
ax2.legend(loc='upper right')

# Creating a third y-axis (rightmost) for Tokens Sold
# This involves a slight offset and width adjustment
ax3 = ax1.twinx()
ax3.spines['right'].set_position(('outward', 60))
ax3.plot(vesting_schedule_original.index, vesting_schedule_original["Tokens Sold"], label='Tokens Sold', color='green', marker='x', markersize=4, linestyle='--')
ax3.set_ylabel('Tokens Sold', color='green')
ax3.legend(loc='upper center')

plt.tight_layout()
plt.show()


